{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder: AE\n",
    "\n",
    "In this notebook we explore the using of AEs for anomaly detection. For this purpose, we will use the following procedure:\n",
    "\n",
    "1. We use the train set for the training process. We use a non-contaminated version of the public test set for validation (to decide early stopping and avoid the overfitting over the training set).\n",
    "2. The performance of the model was measured over the private test set.\n",
    "\n",
    "\n",
    "TODO: \n",
    "1. Check if the performance improves when using QuantileTransform instead of MinMaxScaler. -> QuantileTransform is fundamental.\n",
    "2. Check if the performance improves when using only curves with more than 20 detections in both bands. -> Results improves.\n",
    "3. Check if the performance improves when more importance to the most important features of the Supervised RF-Detector are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from barbar import Bar\n",
    "\n",
    "from preprocess_singlein import get_mnist\n",
    "from ae.train import TrainerAE\n",
    "from ae.test import eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 200\n",
    "    num_epochs = 1000\n",
    "    lr = 1e-4\n",
    "    patience = 100\n",
    "    lr_milestones = [250, 350]\n",
    "    latent_dim = 32\n",
    "    anormal_class = 5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "args = Args() # Parsing all the arguments for the training\n",
    "\n",
    "dataloader_train, dataloader_val, dataloader_test = get_mnist(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 0, Loss: 0.115\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 0, Loss: 0.0595\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 1, Loss: 0.037\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 1, Loss: 0.0234\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 2, Loss: 0.017\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 2, Loss: 0.0134\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 3, Loss: 0.011\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 3, Loss: 0.00948\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 4, Loss: 0.008\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 4, Loss: 0.00752\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 5, Loss: 0.007\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 5, Loss: 0.00642\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 6, Loss: 0.006\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 6, Loss: 0.00563\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 7, Loss: 0.005\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 7, Loss: 0.00516\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 8, Loss: 0.005\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 8, Loss: 0.00482\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 9, Loss: 0.005\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 9, Loss: 0.00448\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 10, Loss: 0.004\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 10, Loss: 0.00421\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 11, Loss: 0.004\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 11, Loss: 0.00399\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 12, Loss: 0.004\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 12, Loss: 0.00383\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 13, Loss: 0.004\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 13, Loss: 0.00374\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 14, Loss: 0.004\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 14, Loss: 0.00362\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 15, Loss: 0.004\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 15, Loss: 0.00357\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 16, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 16, Loss: 0.00341\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 17, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 17, Loss: 0.00333\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 18, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 18, Loss: 0.00346\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 19, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 19, Loss: 0.00325\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 20, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 20, Loss: 0.00319\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 21, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 21, Loss: 0.00314\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 22, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 22, Loss: 0.00308\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 23, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 23, Loss: 0.00323\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 24, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 24, Loss: 0.00299\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 25, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 25, Loss: 0.00299\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 26, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 26, Loss: 0.00304\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 27, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 27, Loss: 0.00299\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 28, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 28, Loss: 0.00288\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 29, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 29, Loss: 0.00286\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 30, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 30, Loss: 0.00283\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 31, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 31, Loss: 0.00291\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 32, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 32, Loss: 0.00277\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 33, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 33, Loss: 0.00295\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 34, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 34, Loss: 0.00288\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 35, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 35, Loss: 0.00294\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 36, Loss: 0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 36, Loss: 0.00269\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 37, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 37, Loss: 0.00266\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 38, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 38, Loss: 0.00269\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 39, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 39, Loss: 0.00265\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 40, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 40, Loss: 0.00267\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 41, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 41, Loss: 0.00265\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 42, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 42, Loss: 0.00265\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 43, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 43, Loss: 0.00255\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 44, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 44, Loss: 0.00261\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 45, Loss: 0.003\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 45, Loss: 0.00262\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 46, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 46, Loss: 0.00273\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 47, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 47, Loss: 0.0025\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 48, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 48, Loss: 0.00253\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 49, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 49, Loss: 0.0025\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 50, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 50, Loss: 0.00246\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 51, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 51, Loss: 0.00252\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 52, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 52, Loss: 0.00243\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 53, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 53, Loss: 0.00251\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 54, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 54, Loss: 0.00247\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 55, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 55, Loss: 0.0025\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 56, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 56, Loss: 0.00243\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 57, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 57, Loss: 0.00246\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 58, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 58, Loss: 0.00244\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 59, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 59, Loss: 0.00238\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 60, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 60, Loss: 0.00251\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 61, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 61, Loss: 0.00234\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 62, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 62, Loss: 0.00244\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 63, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 63, Loss: 0.0025\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 64, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 64, Loss: 0.00237\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 65, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 65, Loss: 0.00238\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 66, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 66, Loss: 0.00232\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 67, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 67, Loss: 0.00233\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 68, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 68, Loss: 0.00234\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 69, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 69, Loss: 0.00229\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 70, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 70, Loss: 0.00228\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 71, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 71, Loss: 0.00231\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 72, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 72, Loss: 0.0027\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 73, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 73, Loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 74, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 74, Loss: 0.00292\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 75, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 75, Loss: 0.00258\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 76, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 76, Loss: 0.00226\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 77, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 77, Loss: 0.0025\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 78, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 78, Loss: 0.0024\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 79, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 79, Loss: 0.00227\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 80, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 80, Loss: 0.00233\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 81, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 81, Loss: 0.00233\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 82, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 82, Loss: 0.00221\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 83, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 83, Loss: 0.00228\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 84, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 84, Loss: 0.00236\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 85, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 85, Loss: 0.0022\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 86, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 86, Loss: 0.00235\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 87, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 87, Loss: 0.00232\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 88, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 88, Loss: 0.00217\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 89, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 89, Loss: 0.00225\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 90, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 90, Loss: 0.00238\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 91, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 91, Loss: 0.00236\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 92, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 92, Loss: 0.00237\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 93, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 93, Loss: 0.00216\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 94, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 94, Loss: 0.00228\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 95, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 95, Loss: 0.00241\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 96, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 96, Loss: 0.0022\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 97, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 97, Loss: 0.00227\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 98, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 98, Loss: 0.0023\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 99, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 99, Loss: 0.00241\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 100, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 100, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 101, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 101, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 102, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 102, Loss: 0.00221\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 103, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 103, Loss: 0.00228\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 104, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 104, Loss: 0.00233\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 105, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 105, Loss: 0.00236\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 106, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 106, Loss: 0.00222\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 107, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 107, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 108, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 108, Loss: 0.00228\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 109, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 109, Loss: 0.00215\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 110, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 110, Loss: 0.00217\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 111, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 111, Loss: 0.00212\n",
      "Weights saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 112, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 112, Loss: 0.00231\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 113, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 113, Loss: 0.00224\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 114, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 114, Loss: 0.00217\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 115, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 115, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 116, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 116, Loss: 0.00225\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 117, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 117, Loss: 0.0025\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 118, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 118, Loss: 0.00212\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 119, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 119, Loss: 0.00242\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 120, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 120, Loss: 0.00255\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 121, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 121, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 122, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 122, Loss: 0.0021\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 123, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 123, Loss: 0.00234\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 124, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 124, Loss: 0.00212\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 125, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 125, Loss: 0.00229\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 126, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 126, Loss: 0.00227\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 127, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 127, Loss: 0.0021\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 128, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 128, Loss: 0.00209\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 129, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 129, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 130, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 130, Loss: 0.00208\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 131, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 131, Loss: 0.00238\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 132, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 132, Loss: 0.00263\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 133, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 133, Loss: 0.00216\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 134, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 134, Loss: 0.00215\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 135, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 135, Loss: 0.00207\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 136, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 136, Loss: 0.0021\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 137, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 137, Loss: 0.00223\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 138, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 138, Loss: 0.00225\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 139, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 139, Loss: 0.00215\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 140, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 140, Loss: 0.00209\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 141, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 141, Loss: 0.00205\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 142, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 142, Loss: 0.00253\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 143, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 143, Loss: 0.00239\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 144, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 144, Loss: 0.00206\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 145, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 145, Loss: 0.0021\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 146, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 146, Loss: 0.0022\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 147, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 147, Loss: 0.0023\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 148, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 148, Loss: 0.00215\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 149, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 149, Loss: 0.00233\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 150, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 150, Loss: 0.00205\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 151, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 151, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 152, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 152, Loss: 0.00219\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 153, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 153, Loss: 0.00213\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 154, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 154, Loss: 0.00224\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 155, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 155, Loss: 0.00203\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 156, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 156, Loss: 0.00211\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 157, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 157, Loss: 0.00224\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 158, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 158, Loss: 0.00206\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 159, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 159, Loss: 0.00215\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 160, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 160, Loss: 0.00205\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 161, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 161, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 162, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 162, Loss: 0.00212\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 163, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 163, Loss: 0.00201\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 164, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 164, Loss: 0.00234\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 165, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 165, Loss: 0.00213\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 166, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 166, Loss: 0.00222\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 167, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 167, Loss: 0.00209\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 168, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 168, Loss: 0.00209\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 169, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 169, Loss: 0.00214\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 170, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 170, Loss: 0.00246\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 171, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 171, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 172, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 172, Loss: 0.00202\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 173, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 173, Loss: 0.00202\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 174, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 174, Loss: 0.00239\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 175, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 175, Loss: 0.00249\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 176, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 176, Loss: 0.00209\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 177, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 177, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 178, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 178, Loss: 0.0022\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 179, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 179, Loss: 0.0021\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 180, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 180, Loss: 0.00206\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 181, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 181, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 182, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 182, Loss: 0.00214\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 183, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 183, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 184, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 184, Loss: 0.00208\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 185, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 185, Loss: 0.00206\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 186, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 186, Loss: 0.0023\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 187, Loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 187, Loss: 0.00216\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 188, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 188, Loss: 0.00201\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 189, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 189, Loss: 0.00206\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 190, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 190, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 191, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 191, Loss: 0.00202\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 192, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 192, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 193, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 193, Loss: 0.0021\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 194, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 194, Loss: 0.00199\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 195, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 195, Loss: 0.0024\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 196, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 196, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 197, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 197, Loss: 0.00227\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 198, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 198, Loss: 0.00214\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 199, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 199, Loss: 0.00202\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 200, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 200, Loss: 0.00219\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 201, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 201, Loss: 0.00219\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 202, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 202, Loss: 0.00226\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 203, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 203, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 204, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 204, Loss: 0.00212\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 205, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 205, Loss: 0.00201\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 206, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 206, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 207, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 207, Loss: 0.00208\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 208, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 208, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 209, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 209, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 210, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 210, Loss: 0.00217\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 211, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 211, Loss: 0.00199\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 212, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 212, Loss: 0.002\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 213, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 213, Loss: 0.00202\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 214, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 214, Loss: 0.00226\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 215, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 215, Loss: 0.00201\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 216, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 216, Loss: 0.00218\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 217, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 217, Loss: 0.00209\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 218, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 218, Loss: 0.00214\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 219, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 219, Loss: 0.0023\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 220, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 220, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 221, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 221, Loss: 0.00211\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 222, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 222, Loss: 0.00217\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 223, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 223, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 224, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 224, Loss: 0.00194\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 225, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 225, Loss: 0.00202\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 226, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 226, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 227, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 227, Loss: 0.00205\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 228, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 228, Loss: 0.00212\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 229, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 229, Loss: 0.00208\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 230, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 230, Loss: 0.00199\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 231, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 231, Loss: 0.00211\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 232, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 232, Loss: 0.00208\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 233, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 233, Loss: 0.00204\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 234, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 234, Loss: 0.00204\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 235, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 235, Loss: 0.00217\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 236, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 236, Loss: 0.00212\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 237, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 237, Loss: 0.00216\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 238, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 238, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 239, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 239, Loss: 0.00203\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 240, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 240, Loss: 0.00196\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 241, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 241, Loss: 0.00198\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 242, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 242, Loss: 0.00219\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 243, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 243, Loss: 0.00213\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 244, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 244, Loss: 0.00213\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 245, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 245, Loss: 0.00211\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 246, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 246, Loss: 0.00207\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 247, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 247, Loss: 0.00197\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 248, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 248, Loss: 0.002\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 249, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 249, Loss: 0.00216\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 250, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 250, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 251, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 251, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 252, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 252, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 253, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 253, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 254, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 254, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 255, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 255, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 256, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 256, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 257, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 257, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 258, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 258, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 259, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 259, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 260, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 260, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 261, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 261, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 262, Loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 262, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 263, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 263, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 264, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 264, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 265, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 265, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 266, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 266, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 267, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 267, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 268, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 268, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 269, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 269, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 270, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 270, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 271, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 271, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 272, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 272, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 273, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 273, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 274, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 274, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 275, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 275, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 276, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 276, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 277, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 277, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 278, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 278, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 279, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 279, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 280, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 280, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 281, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 281, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 282, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 282, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 283, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 283, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 284, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 284, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 285, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 285, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 286, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 286, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 287, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 287, Loss: 0.00187\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 288, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 288, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 289, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 289, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 290, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 290, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 291, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 291, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 292, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 292, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 293, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 293, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 294, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 294, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 295, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 295, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 296, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 296, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 297, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 297, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 298, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 298, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 299, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 299, Loss: 0.00187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 300, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 300, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 301, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 301, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 302, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 302, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 303, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 303, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 304, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 304, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 305, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 305, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 306, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 306, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 307, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 307, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 308, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 308, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 309, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 309, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 310, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 310, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 311, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 311, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 312, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 312, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 313, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 313, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 314, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 314, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 315, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 315, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 316, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 316, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 317, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 317, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 318, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 318, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 319, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 319, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 320, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 320, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 321, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 321, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 322, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 322, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 323, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 323, Loss: 0.00186\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 324, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 324, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 325, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 325, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 326, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 326, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 327, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 327, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 328, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 328, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 329, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 329, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 330, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 330, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 331, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 331, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 332, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 332, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 333, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 333, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 334, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 334, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 335, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 335, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 336, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 336, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 337, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 337, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 338, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 338, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 339, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 339, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 340, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 340, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 341, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 341, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 342, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 342, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 343, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 343, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 344, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 344, Loss: 0.00187\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 345, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 345, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 346, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 346, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 347, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 347, Loss: 0.00188\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 348, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 348, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 349, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 349, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 350, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 350, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 351, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 351, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 352, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 352, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 353, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 353, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 354, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 354, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 355, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 355, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 356, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 356, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 357, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 357, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 358, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 358, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 359, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 359, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 360, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 360, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 361, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 361, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 362, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 362, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 363, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 363, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 364, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 364, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 365, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 365, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 366, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 366, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 367, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 367, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 368, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 368, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 369, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 369, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 370, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 370, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 371, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 371, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 372, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 372, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 373, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 373, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 374, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 374, Loss: 0.00185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 375, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 375, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 376, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 376, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 377, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 377, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 378, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 378, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 379, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 379, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 380, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 380, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 381, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 381, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 382, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 382, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 383, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 383, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 384, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 384, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 385, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 385, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 386, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 386, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 387, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 387, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 388, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 388, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 389, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 389, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 390, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 390, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 391, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 391, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 392, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 392, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 393, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 393, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 394, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 394, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 395, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 395, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 396, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 396, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 397, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 397, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 398, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 398, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 399, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 399, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 400, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 400, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 401, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 401, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 402, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 402, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 403, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 403, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 404, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 404, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 405, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 405, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 406, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 406, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 407, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 407, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 408, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 408, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 409, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 409, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 410, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 410, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 411, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 411, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 412, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 412, Loss: 0.00185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 413, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 413, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 414, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 414, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 415, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 415, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 416, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 416, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 417, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 417, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 418, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 418, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 419, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 419, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 420, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 420, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 421, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 421, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 422, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 422, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 423, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 423, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 424, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 424, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 425, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 425, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 426, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 426, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 427, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 427, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 428, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 428, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 429, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 429, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 430, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 430, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 431, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 431, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 432, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 432, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 433, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 433, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 434, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 434, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 435, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 435, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 436, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 436, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 437, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 437, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 438, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 438, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 439, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 439, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 440, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 440, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 441, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 441, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 442, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 442, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 443, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 443, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 444, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 444, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 445, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 445, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 446, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 446, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 447, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 447, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 448, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 448, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 449, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 449, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 450, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 450, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 451, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 451, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 452, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 452, Loss: 0.00185\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 453, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 453, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 454, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 454, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 455, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 455, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 456, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 456, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 457, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 457, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 458, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 458, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 459, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 459, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 460, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 460, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 461, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 461, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 462, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 462, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 463, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 463, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 464, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 464, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 465, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 465, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 466, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 466, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 467, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 467, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 468, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 468, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 469, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 469, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 470, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 470, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 471, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 471, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 472, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 472, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 473, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 473, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 474, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 474, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 475, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 475, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 476, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 476, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 477, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 477, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 478, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 478, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 479, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 479, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 480, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 480, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 481, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 481, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 482, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 482, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 483, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 483, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 484, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 484, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 485, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 485, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 486, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 486, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 487, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 487, Loss: 0.00185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 488, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 488, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 489, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 489, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 490, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 490, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 491, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 491, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 492, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 492, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 493, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 493, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 494, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 494, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 495, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 495, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 496, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 496, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 497, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 497, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 498, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 498, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 499, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 499, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 500, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 500, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 501, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 501, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 502, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 502, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 503, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 503, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 504, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 504, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 505, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 505, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 506, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 506, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 507, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 507, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 508, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 508, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 509, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 509, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 510, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 510, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 511, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 511, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 512, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 512, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 513, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 513, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 514, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 514, Loss: 0.00186\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 515, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 515, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 516, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 516, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 517, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 517, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 518, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 518, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 519, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 519, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 520, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 520, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 521, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 521, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 522, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 522, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 523, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 523, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 524, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 524, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 525, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 525, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 526, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 526, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 527, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 527, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 528, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 528, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 529, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 529, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 530, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 530, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 531, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 531, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 532, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 532, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 533, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 533, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 534, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 534, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 535, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 535, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 536, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 536, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 537, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 537, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 538, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 538, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 539, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 539, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 540, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 540, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 541, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 541, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 542, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 542, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 543, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 543, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 544, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 544, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 545, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 545, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 546, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 546, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 547, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 547, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 548, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 548, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 549, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 549, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 550, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 550, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 551, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 551, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 552, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 552, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 553, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 553, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 554, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 554, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 555, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 555, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 556, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 556, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 557, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 557, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 558, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 558, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 559, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 559, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 560, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 560, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 561, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 561, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 562, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 562, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 563, Loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 563, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 564, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 564, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 565, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 565, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 566, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 566, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 567, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 567, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 568, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 568, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 569, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 569, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 570, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 570, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 571, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 571, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 572, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 572, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 573, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 573, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 574, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 574, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 575, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 575, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 576, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 576, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 577, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 577, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 578, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 578, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 579, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 579, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 580, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 580, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 581, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 581, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 582, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 582, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 583, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 583, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 584, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 584, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 585, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 585, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 586, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 586, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 587, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 587, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 588, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 588, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 589, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 589, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 590, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 590, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 591, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 591, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 592, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 592, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 593, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 593, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 594, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 594, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 595, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 595, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 596, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 596, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 597, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 597, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 598, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 598, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 599, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 599, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 600, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 600, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 601, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 601, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 602, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 602, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 603, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 603, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 604, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 604, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 605, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 605, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 606, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 606, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 607, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 607, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 608, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 608, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 609, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 609, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 610, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 610, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 611, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 611, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 612, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 612, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 613, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 613, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 614, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 614, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 615, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 615, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 616, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 616, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 617, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 617, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 618, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 618, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 619, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 619, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 620, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 620, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 621, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 621, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 622, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 622, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 623, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 623, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 624, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 624, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 625, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 625, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 626, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 626, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 627, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 627, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 628, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 628, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 629, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 629, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 630, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 630, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 631, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 631, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 632, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 632, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 633, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 633, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 634, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 634, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 635, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 635, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 636, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 636, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 637, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 637, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 638, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 638, Loss: 0.00184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 639, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 639, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 640, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 640, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 641, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 641, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 642, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 642, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 643, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 643, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 644, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 644, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 645, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 645, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 646, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 646, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 647, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 647, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 648, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 648, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 649, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 649, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 650, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 650, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 651, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 651, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 652, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 652, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 653, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 653, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 654, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 654, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 655, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 655, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 656, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 656, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 657, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 657, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 658, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 658, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 659, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 659, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 660, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 660, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 661, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 661, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 662, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 662, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 663, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 663, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 664, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 664, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 665, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 665, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 666, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 666, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 667, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 667, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 668, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 668, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 669, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 669, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 670, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 670, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 671, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 671, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 672, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 672, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 673, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 673, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 674, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 674, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 675, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 675, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 676, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 676, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 677, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 677, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 678, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 678, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 679, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 679, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 680, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 680, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 681, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 681, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 682, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 682, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 683, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 683, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 684, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 684, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 685, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 685, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 686, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 686, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 687, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 687, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 688, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 688, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 689, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 689, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 690, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 690, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 691, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 691, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 692, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 692, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 693, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 693, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 694, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 694, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 695, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 695, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 696, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 696, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 697, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 697, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 698, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 698, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 699, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 699, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 700, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 700, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 701, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 701, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 702, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 702, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 703, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 703, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 704, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 704, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 705, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 705, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 706, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 706, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 707, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 707, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 708, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 708, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 709, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 709, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 710, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 710, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 711, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 711, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 712, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 712, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 713, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 713, Loss: 0.00184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 714, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 714, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 715, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 715, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 716, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 716, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 717, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 717, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 718, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 718, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 719, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 719, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 720, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 720, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 721, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 721, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 722, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 722, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 723, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 723, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 724, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 724, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 725, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 725, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 726, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 726, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 727, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 727, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 728, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 728, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 729, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 729, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 730, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 730, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 731, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 731, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 732, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 732, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 733, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 733, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 734, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 734, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 735, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 735, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 736, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 736, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 737, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 737, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 738, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 738, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 739, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 739, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 740, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 740, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 741, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 741, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 742, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 742, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 743, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 743, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 744, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 744, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 745, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 745, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 746, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 746, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 747, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 747, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 748, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 748, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 749, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 749, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 750, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 750, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 751, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 751, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 752, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 752, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 753, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 753, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 754, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 754, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 755, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 755, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 756, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 756, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 757, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 757, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 758, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 758, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 759, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 759, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 760, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 760, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 761, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 761, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 762, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 762, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 763, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 763, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 764, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 764, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 765, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 765, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 766, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 766, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 767, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 767, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 768, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 768, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 769, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 769, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 770, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 770, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 771, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 771, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 772, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 772, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 773, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 773, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 774, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 774, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 775, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 775, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 776, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 776, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 777, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 777, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 778, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 778, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 779, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 779, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 780, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 780, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 781, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 781, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 782, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 782, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 783, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 783, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 784, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 784, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 785, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 785, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 786, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 786, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 787, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 787, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 788, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 788, Loss: 0.00184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 789, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 789, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 790, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 790, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 791, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 791, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 792, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 792, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 793, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 793, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 794, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 794, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 795, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 795, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 796, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 796, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 797, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 797, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 798, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 798, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 799, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 799, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 800, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 800, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 801, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 801, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 802, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 802, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 803, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 803, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 804, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 804, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 805, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 805, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 806, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 806, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 807, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 807, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 808, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 808, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 809, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 809, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 810, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 810, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 811, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 811, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 812, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 812, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 813, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 813, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 814, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 814, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 815, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 815, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 816, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 816, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 817, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 817, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 818, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 818, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 819, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 819, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 820, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 820, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 821, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 821, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 822, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 822, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 823, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 823, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 824, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 824, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 825, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 825, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 826, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 826, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 827, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 827, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 828, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 828, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 829, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 829, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 830, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 830, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 831, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 831, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 832, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 832, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 833, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 833, Loss: 0.00185\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 834, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 834, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 835, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 835, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 836, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 836, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 837, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 837, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 838, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 838, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 839, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 839, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 840, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 840, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 841, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 841, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 842, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 842, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 843, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 843, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 844, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 844, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 845, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 845, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 846, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 846, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 847, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 847, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 848, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 848, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 849, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 849, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 850, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 850, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 851, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 851, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 852, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 852, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 853, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 853, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 854, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 854, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 855, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 855, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 856, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 856, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 857, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 857, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 858, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 858, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 859, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 859, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 860, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 860, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 861, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 861, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 862, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 862, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 863, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 863, Loss: 0.00184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 864, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 864, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 865, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 865, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 866, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 866, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 867, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 867, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 868, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 868, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 869, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 869, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 870, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 870, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 871, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 871, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 872, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 872, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 873, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 873, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 874, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 874, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 875, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 875, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 876, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 876, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 877, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 877, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 878, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 878, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 879, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 879, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 880, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 880, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 881, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 881, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 882, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 882, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 883, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 883, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 884, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 884, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 885, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 885, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 886, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 886, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 887, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 887, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 888, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 888, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 889, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 889, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 890, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 890, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 891, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 891, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 892, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 892, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 893, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 893, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 894, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 894, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 895, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 895, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 896, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 896, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 897, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 897, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 898, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 898, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 899, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 899, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 900, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 900, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 901, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 901, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 902, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 902, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 903, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 903, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 904, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 904, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 905, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 905, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 906, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 906, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 907, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 907, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 908, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 908, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 909, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 909, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 910, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 910, Loss: 0.00184\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 911, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 911, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 912, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 912, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 913, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 913, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 914, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 914, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 915, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 915, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 916, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 916, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 917, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 917, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 918, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 918, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 919, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 919, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 920, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 920, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 921, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 921, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 922, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 922, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 923, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 923, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 924, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 924, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 925, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 925, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 926, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 926, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 927, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 927, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 928, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 928, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 929, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 929, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 930, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 930, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 931, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 931, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 932, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 932, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 933, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 933, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 934, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 934, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 935, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 935, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 936, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 936, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 937, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 937, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 938, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 938, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 939, Loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 939, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 940, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 940, Loss: 0.00183\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 941, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 941, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 942, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 942, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 943, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 943, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 944, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 944, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 945, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 945, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 946, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 946, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 947, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 947, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 948, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 948, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 949, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 949, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 950, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 950, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 951, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 951, Loss: 0.00183\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 952, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 952, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 953, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 953, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 954, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 954, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 955, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 955, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 956, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 956, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 957, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 957, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 958, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 958, Loss: 0.00183\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 959, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 959, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 960, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 960, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 961, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 961, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 962, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 962, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 963, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 963, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 964, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 964, Loss: 0.00183\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 965, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 965, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 966, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 966, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 967, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 967, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 968, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 968, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 969, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 969, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 970, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 970, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 971, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 971, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 972, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 972, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 973, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 973, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 974, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 974, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 975, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 975, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 976, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 976, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 977, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 977, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 978, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 978, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 979, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 979, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 980, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 980, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 981, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 981, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 982, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 982, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 983, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 983, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 984, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 984, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 985, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 985, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 986, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 986, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 987, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 987, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 988, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 988, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 989, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 989, Loss: 0.00183\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 990, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 990, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 991, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 991, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 992, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 992, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 993, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 993, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 994, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing Autoencoder... Epoch: 994, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 995, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 995, Loss: 0.00184\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 996, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 996, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 997, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 997, Loss: 0.00183\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 998, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 998, Loss: 0.00183\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training Autoencoder... Epoch: 999, Loss: 0.002\n",
      "10652/10652: [===============================>] - ETA 0.1s\n",
      "Testing Autoencoder... Epoch: 999, Loss: 0.00183\n"
     ]
    }
   ],
   "source": [
    "ae = TrainerAE(args, dataloader_train, dataloader_val, device)\n",
    "ae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(values, values_t, metric):\n",
    "    plt.plot(np.arange(len(values)), values, c='k', label='train')\n",
    "    plt.plot(np.arange(len(values_t)), values_t, c='b', label='test')\n",
    "    plt.title('Autoencoder {}'.format(metric))\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(np.array(ae.reconst), np.array(ae.reconst_t), 'Reconstruction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "ROC AUC score: 0.551\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def eval(net, dataloader, device):\n",
    "    \"\"\"Testing the Autoencoder model\"\"\"\n",
    "\n",
    "    scores = []\n",
    "    latents = []\n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "    net.eval()\n",
    "    print('Testing...')\n",
    "    with torch.no_grad():\n",
    "        for x, y1, y2 in dataloader:\n",
    "            x = x.float().to(device)\n",
    "            x_hat, z = net(x)\n",
    "            score = F.mse_loss(x_hat, x, reduction='none')\n",
    "            score = torch.sum(score, dim=(1,2,3))\n",
    "\n",
    "            scores.append(score.detach().cpu())\n",
    "            latents.append(z.detach().cpu())\n",
    "            labels1.append(y1.cpu())\n",
    "            labels2.append(y2.cpu())\n",
    "    labels1, labels2 = torch.cat(labels1).numpy(), torch.cat(labels2).numpy()\n",
    "    scores, latents = torch.cat(scores).numpy(), torch.cat(latents).numpy()\n",
    "    print('ROC AUC score: {:.3f}'.format(roc_auc_score(labels2, scores)))\n",
    "    return labels1, labels2, scores, latents\n",
    "\n",
    "labels1, labels2, scores, latent = eval(ae.model, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=2).fit_transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cmap = plt.get_cmap('jet', 4)\n",
    "plt.scatter(x_embedded[:, 0][labels2==0], x_embedded[:, 1][labels2==0],\n",
    "            s=15, alpha=0.5, marker='.')\n",
    "plt.scatter(x_embedded[:, 0][labels2!=0], x_embedded[:, 1][labels2!=0], \n",
    "            c=labels2[labels2!=0].reshape(-1,),\n",
    "            s=150, cmap=cmap, marker='*')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_in = scores[labels1==0]\n",
    "scores_out = scores[labels1==1]\n",
    "\n",
    "scores_ELL = scores[labels2==1]\n",
    "scores_TDE = scores[labels2==2]\n",
    "scores_SNIIb = scores[labels2==3]\n",
    "scores_WRayot = scores[labels2==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f93e24b78d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGEVJREFUeJzt3X+QVeWd5/H3Z9rGHn8babOGpgVrrUREgti2M0tqgmOChBWxErcGYjJoaXVqIjGZSWVLkyqc1YS4a2rMTPzJaq/jRCEzGFOwS0bZGMaJUaFRgvyIQggJnXYHhIwGBRX47h/3NLm2t/uevn2774Xn86q61fc85znnfi+2n/v0c849RxGBmZml4w9qXYCZmY0sB7+ZWWIc/GZmiXHwm5klxsFvZpYYB7+ZWWIc/GZmiXHwm5klpmzwSxor6ceSNkvaKOmLJfpI0t9J2ippvaQpRevmSdqSPeZV+w2YmdngqNw3dyWdAZwREc9LOhFYC1wREZuK+swEvgDMBC4C/jYiLpL0PqALaAMi2/aCiPjtQK85evToGDduXOXvyswsMWvXrn01Iprz9D2mXIeIeAV4JXv+O0mbgTHApqJus4GHovAp8qykU7IPjGnAyojYAyBpJTADWDzQa44bN46urq489ZuZGSDpV3n7DmqOX9I44HzguT6rxgA7ipa7s7b+2kvtu0NSl6SuXbt2DaYsMzMbhNzBL+kE4FHgSxHxet/VJTaJAdrf2xixKCLaIqKtuTnXXytmZlaBXMEvqZFC6D8cEd8v0aUbGFu03AL0DNBuZmY1UnaOX5KAB4DNEfE3/XRbBsyXtITCwd3XIuIVSY8DCyWdmvWbDtxUhbrNLAHvvPMO3d3d7N+/v9al1I2mpiZaWlpobGyseB9lgx+YCnwWeFHSuqztq0ArQETcC6ygcEbPVuBN4Jps3R5JtwJrsu1u6T3Qa2ZWTnd3NyeeeCLjxo2jMAZNW0Swe/duuru7GT9+fMX7yXNWz08oPVdf3CeA6/tZ1wl0VlSdmSVt//79Dv0ikjjttNMY6gkw/uaumdU1h/67VePfw8FvZpaYPHP8ZmZ1Yfny6u5v1qzyfU444QT27t07YJ9p06bxrW99i7a2NmbOnMkjjzzCKaecUqUqqy+p4C/+pcnzH9zMbLBWrFgxqP4HDx6koaFhmKopzVM9ZmY5rFq1imnTpnHllVfyoQ99iKuuuopS1zobN24cr776KgDf/e53aW9vZ/LkyXzuc5/j4MGDQOGviAULFnDRRRfxzDPPjOj7AAe/mVluL7zwAt/+9rfZtGkT27Zt4+mnn+637+bNm/ne977H008/zbp162hoaODhhx8G4I033mDixIk899xzfOQjHxmp8g9LaqrHzGwo2tvbaWlpAWDy5Mls37693+D+0Y9+xNq1a7nwwgsB2LdvH6effjoADQ0NfOpTnxqZoktw8JuZ5XTsscceft7Q0MCBAwf67RsRzJs3j29+85vvWdfU1DTi8/rFPNVjZjYMLrnkEpYuXcrOnTsB2LNnD7/6Ve4rJw8rj/jN7IhxJJ2NN2HCBL7+9a8zffp0Dh06RGNjI3fddRdnnnlmrUsrfweuWmhra4vhuBGLT+c0O7Js3ryZc845p9Zl1J1S/y6S1kZEW57tPdVjZpYYB7+ZWWIc/GZmiXHwm5klxsFvZpYYB7+ZWWJ8Hr+ZHTlqcV1mCreAvP7669m0aROHDh3isssu4/bbb2fUqFH9brNw4UK++tWvHl7uvbxzT08PN9xwA0uXLh1y+ZUqO+KX1Clpp6QN/az/iqR12WODpIOS3pet2y7pxWxd9U/MNzMbZhHBJz/5Sa644gq2bNnCyy+/zN69e/na17424HYLFy4s2f6BD3xgUKHfe0XPasoz1fMgMKO/lRFxe0RMjojJwE3Av/S5ofrF2fpcXywwM6snTz75JE1NTVxzzTVA4Ro9d9xxB52dndx9993Mnz//cN/LLruMVatWceONN7Jv3z4mT57MVVdd9a79bd++nYkTJwKFUP/KV77ChRdeyKRJk7jvvvuAwiWgL774Yj796U9z3nnnVf095bnZ+lOSxuXc31xg8VAKMjOrJxs3buSCCy54V9tJJ51Ea2trvxdpu+2227jzzjtZt27dgPt+4IEHOPnkk1mzZg1vvfUWU6dOZfr06QCsXr2aDRs2MH78+Oq8kSJVm+OXdByFvwzmFzUH8ISkAO6LiEUDbN8BdAC0trZWqywzsyGJiJI3OO+vfTCeeOIJ1q9ff3jq57XXXmPLli2MGjWK9vb2YQl9qO7B3VnA032meaZGRI+k04GVkn4eEU+V2jj7UFgEhWv1VLEuM7OKnXvuuTz66KPvanv99dfZsWMHJ598MocOHTrcvn///kHtOyL4zne+w6WXXvqu9lWrVnH88cdXXnQZ1Tydcw59pnkioif7uRN4DGiv4utVxfLlv3+YmfV1ySWX8Oabb/LQQw8BhXn5L3/5y1x99dWcddZZrFu3jkOHDrFjxw5Wr159eLvGxkbeeeedAfd96aWXcs899xzu9/LLL/PGG28M35vJVGXEL+lk4KPAZ4rajgf+ICJ+lz2fDtxSjdczs0TV4LK6knjsscf4/Oc/z6233sqhQ4eYOXMmCxcuZNSoUYwfP57zzjuPiRMnMmXKlMPbdXR0MGnSJKZMmXL4lot9XXfddWzfvp0pU6YQETQ3N/ODH/xg+N9TucsyS1oMTANGA/8G3Aw0AkTEvVmfq4EZETGnaLuzKIzyofAB80hEfCNPUdW+LHOp0Xzv748v1WxWv3xZ5tKGelnmPGf1zM3R50EKp30Wt20DPpynCDMzGzm+ZIOZWWIc/GZW1+rxLoG1VI1/Dwe/mdWtpqYmdu/e7fDPRAS7d++mqalpSPvxRdrMrG61tLTQ3d3Nrl27al1K3WhqaqKlpWVI+3Dwm1ndamxsHLZvr6bMUz1mZolx8JuZJcbBb2aWGAe/mVliHPxmZolx8JuZJcbBb2aWGAe/mVliHPxmZolx8JuZJcbBb2aWGAe/mVliHPxmZokpG/ySOiXtlLShn/XTJL0maV32WFC0boaklyRtlXRjNQs3M7PK5BnxPwjMKNPnXyNicva4BUBSA3AX8AlgAjBX0oShFGtmZkNXNvgj4ilgTwX7bge2RsS2iHgbWALMrmA/ZmZWRdWa4/9jST+T9ENJ52ZtY4AdRX26s7aSJHVI6pLU5bvtmJkNn2oE//PAmRHxYeA7wA+ydpXo2++NMyNiUUS0RURbc3NzFcoyM7NShhz8EfF6ROzNnq8AGiWNpjDCH1vUtQXoGerrmZnZ0Aw5+CX9B0nKnrdn+9wNrAHOljRe0ihgDrBsqK9nZmZDU/Zm65IWA9OA0ZK6gZuBRoCIuBe4EvgLSQeAfcCciAjggKT5wONAA9AZERuH5V2YmVluZYM/IuaWWX8ncGc/61YAKyorbXgtX17rCszMasPf3DUzS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS0zZ4JfUKWmnpA39rL9K0vrs8VNJHy5at13Si5LWSeqqZuFmZlaZPCP+B4EZA6z/JfDRiJgE3Aos6rP+4oiYHBFtlZVoZmbVlOeeu09JGjfA+p8WLT4LtAy9LDMzGy7VnuO/Fvhh0XIAT0haK6mjyq9lZmYVKDviz0vSxRSC/yNFzVMjokfS6cBKST+PiKf62b4D6ABobW2tVlmDsnx54eesWTV5eTOzEVGVEb+kScD9wOyI2N3bHhE92c+dwGNAe3/7iIhFEdEWEW3Nzc3VKMvMzEoYcvBLagW+D3w2Il4uaj9e0om9z4HpQMkzg8zMbOSUneqRtBiYBoyW1A3cDDQCRMS9wALgNOBuSQAHsjN43g88lrUdAzwSEf88DO/BzMwGIc9ZPXPLrL8OuK5E+zbgw+/dwszMasnf3DUzS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMbmCX1KnpJ2SSt4sXQV/J2mrpPWSphStmydpS/aYV63CzcysMnlH/A8CMwZY/wng7OzRAdwDIOl9FG7OfhHQDtws6dRKizUzs6HLFfwR8RSwZ4Aus4GHouBZ4BRJZwCXAisjYk9E/BZYycAfIGZmNsyOqdJ+xgA7ipa7s7b+2o8My5dXvu2sWdWrw8ysiqp1cFcl2mKA9vfuQOqQ1CWpa9euXVUqy8zM+qpW8HcDY4uWW4CeAdrfIyIWRURbRLQ1NzdXqSwzM+urWsG/DPjz7OyePwJei4hXgMeB6ZJOzQ7qTs/azMysRnLN8UtaDEwDRkvqpnCmTiNARNwLrABmAluBN4FrsnV7JN0KrMl2dUtEDHSQ2MzMhlmu4I+IuWXWB3B9P+s6gc7Bl2ZmZsPB39w1M0uMg9/MLDEOfjOzxDj4zcwS4+A3M0uMg9/MLDEOfjOzxDj4zcwS4+A3M0uMg9/MLDEOfjOzxFTrRix1Zyj3UDEzO5p5xG9mlpijdsQ/FL1/Lbx/NbS317YWM7Nq84jfzCwxDn4zs8Q4+M3MEuPgNzNLTK7glzRD0kuStkq6scT6OyStyx4vS/r3onUHi9Ytq2bxZmY2eGXP6pHUANwFfBzoBtZIWhYRm3r7RMRfFvX/AnB+0S72RcTk6pVsZmZDkWfE3w5sjYhtEfE2sASYPUD/ucDiahRnZmbVlyf4xwA7ipa7s7b3kHQmMB54sqi5SVKXpGclXVFxpWZmVhV5vsClEm3RT985wNKIOFjU1hoRPZLOAp6U9GJE/OI9LyJ1AB0Ara2tOcoyM7NK5BnxdwNji5ZbgJ5++s6hzzRPRPRkP7cBq3j3/H9xv0UR0RYRbc3NzTnKMjOzSuQJ/jXA2ZLGSxpFIdzfc3aOpA8CpwLPFLWdKunY7PloYCqwqe+2ZmY2cspO9UTEAUnzgceBBqAzIjZKugXoiojeD4G5wJKIKJ4GOge4T9IhCh8ytxWfDWRmZiMv10XaImIFsKJP24I+y39dYrufAucNoT4zM6syf3PXzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIO/SlavLjzMzOqdg9/MLDEO/jI8kjezo42D38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPgr4FM8zexIliv4Jc2Q9JKkrZJuLLH+akm7JK3LHtcVrZsnaUv2mFfN4s3MbPDK3nNXUgNwF/BxoBtYI2lZiZumfy8i5vfZ9n3AzUAbEMDabNvfVqX6EeQRvpkdLfKM+NuBrRGxLSLeBpYAs3Pu/1JgZUTsycJ+JTCjslLNzKwa8gT/GGBH0XJ31tbXpyStl7RU0thBbmtmZiMkT/CrRFv0WV4OjIuIScD/Bf5+ENsWOkodkrokde3atStHWfWp98Dv8uW1rsTMrLQ8wd8NjC1abgF6ijtExO6IeCtb/J/ABXm3LdrHoohoi4i25ubmPLWbmVkF8gT/GuBsSeMljQLmAMuKO0g6o2jxcmBz9vxxYLqkUyWdCkzP2szMrEbKntUTEQckzacQ2A1AZ0RslHQL0BURy4AbJF0OHAD2AFdn2+6RdCuFDw+AWyJizzC8j369f7XnXMzMipUNfoCIWAGs6NO2oOj5TcBN/WzbCXQOoUYzM6uiXMFvpQ10bv+Q/tKYNavybc3MyvAlG8zMEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEpMr+CXNkPSSpK2Sbiyx/q8kbZK0XtKPJJ1ZtO6gpHXZY1nfbc3MbGSVvfWipAbgLuDjQDewRtKyiNhU1O0FoC0i3pT0F8D/AP4sW7cvIiZXue5+La/De6sX36Kxvb12dZiZQb4RfzuwNSK2RcTbwBJgdnGHiPhxRLyZLT4LtFS3TDMzq5Y8wT8G2FG03J219eda4IdFy02SuiQ9K+mKCmo8qqxePfBN2s3MhlvZqR5AJdqiZEfpM0Ab8NGi5taI6JF0FvCkpBcj4hcltu0AOgBaW1tzlGVmZpXIM+LvBsYWLbcAPX07SfoY8DXg8oh4q7c9Inqyn9uAVcD5pV4kIhZFRFtEtDU3N+d+A/XMo3szq0d5RvxrgLMljQd+A8wBPl3cQdL5wH3AjIjYWdR+KvBmRLwlaTQwlcKBXxvIUI5Qz5pVvTrM7KhUNvgj4oCk+cDjQAPQGREbJd0CdEXEMuB24ATgnyQB/DoiLgfOAe6TdIjCXxe39TkbKFk+08fMaiXPiJ+IWAGs6NO2oOj5x/rZ7qfAeUMpMAW9HwL+ADCzkeBv7pqZJcbBb2aWGAe/mVliHPxmZolx8JuZJcbBb2aWGAe/mVliHPxmZonJ9QUuGxmlvs1brq3vOl/uwczK8YjfzCwxDn4zs8Q4+M3MEuM5fvs9Hx8wS4KDv06VOoA72Ju6jOiln/2hYXbE8FSPmVliPOI/CtX1XwZmVnMe8ZuZJcYj/sTkHd37rmBmR69cwS9pBvC3FO65e39E3NZn/bHAQ8AFwG7gzyJie7buJuBa4CBwQ0Q8XrXq7bBy0zt5p3/69qvWNNCAHyRDOTA8FD6obIkqO9UjqQG4C/gEMAGYK2lCn27XAr+NiP8I3AH892zbCcAc4FxgBnB3tj8zM6uRPCP+dmBrRGwDkLQEmA1sKuozG/jr7PlS4E5JytqXRMRbwC8lbc3290x1yrehGOxB4IH2Ua0poVL7y9s2aLU6BdWnvlqN5Qn+McCOouVu4KL++kTEAUmvAadl7c/22XZMxdWa1YtaTU8NxZFY81D4Q7JfeYJfJdoiZ5882xZ2IHUAHdniXkkv5ahtpI0GXq11Ef1wbZVxbZVxbZUbrvrOzNsxT/B3A2OLlluAnn76dEs6BjgZ2JNzWwAiYhGwKF/ZtSGpKyLaal1HKa6tMq6tMq6tcvVQX57z+NcAZ0saL2kUhYO1y/r0WQbMy55fCTwZEZG1z5F0rKTxwNlAFWaWzcysUmVH/Nmc/XzgcQqnc3ZGxEZJtwBdEbEMeAD4h+zg7R4KHw5k/f6RwoHgA8D1EXFwmN6LmZnlkOs8/ohYAazo07ag6Pl+4L/0s+03gG8MocZ6Us9TUa6tMq6tMq6tcjWvT4UZGTMzS4Wv1WNmlhgHfw6SOiXtlLSh1rX0JWmspB9L2ixpo6Qv1rqmXpKaJK2W9LOstv9W65qKSWqQ9IKk/13rWvqStF3Si5LWSeqqdT3FJJ0iaamkn2e/d39c65oAJH0w+/fqfbwu6Uu1rquXpL/M/j/YIGmxpKaa1eKpnvIk/QmwF3goIibWup5iks4AzoiI5yWdCKwFroiITWU2HXbZt7ePj4i9khqBnwBfjIhny2w6IiT9FdAGnBQRl9W6nmKStgNtEVF356NL+nvgXyPi/uxMv+Mi4t9rXVex7NIwvwEuiohf1UE9Yyj8/k+IiH3ZSS8rIuLBWtTjEX8OEfEUhbOV6k5EvBIRz2fPfwdspk6+HR0Fe7PFxuxRFyMNSS3Afwbur3UtRxJJJwF/QuFMPiLi7XoL/cwlwC/qIfSLHAP8YfZdp+Po5ztNI8HBfxSRNA44H3iutpX8Xjadsg7YCayMiHqp7dvAfwUO1bqQfgTwhKS12bfa68VZwC7gf2XTZPdLOr7WRZUwB1hc6yJ6RcRvgG8BvwZeAV6LiCdqVY+D/ygh6QTgUeBLEfF6revpFREHI2IyhW9tt0uq+VSZpMuAnRGxtta1DGBqREyhcFXc67PpxnpwDDAFuCcizgfeAG6sbUnvlk0/XQ78U61r6SXpVAoXrRwPfAA4XtJnalWPg/8okM2fPwo8HBHfr3U9pWTTAasoXJ671qYCl2fz6EuAP5X03dqW9G4R0ZP93Ak8RuGqtvWgG+gu+sttKYUPgnryCeD5iPi3WhdS5GPALyNiV0S8A3wf+E+1KsbBf4TLDqA+AGyOiL+pdT3FJDVLOiV7/ocUfvl/XtuqICJuioiWiBhHYUrgyYio2eirL0nHZwfqyaZRpgN1cUZZRPw/YIekD2ZNl/DuS7TXg7nU0TRP5tfAH0k6Lvt/9hIKx+NqwsGfg6TFFO4h8EFJ3ZKurXVNRaYCn6Uwau09jW1mrYvKnAH8WNJ6Ctd8WhkRdXfqZB16P/ATST+jcG2r/xMR/1zjmop9AXg4++86GVhY43oOk3Qc8HEKI+q6kf2FtBR4HniRQvbW7Bu8Pp3TzCwxHvGbmSXGwW9mlhgHv5lZYhz8ZmaJcfCbmSXGwW9mlhgHv5lZYhz8ZmaJ+f+f6qa+DHSmWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores_in, bins=50, color='b', alpha=0.3, density=True, label='Inlier')\n",
    "plt.hist(scores_out, bins=20, color='r', alpha=0.3, density=True, label='Outlier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
