{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from vade.train import TrainerVaDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def global_contrast_normalization(x):\n",
    "    \"\"\"Apply global contrast normalization to tensor. \"\"\"\n",
    "    mean = torch.mean(x)  # mean over all features (pixels) per sample\n",
    "    x -= mean\n",
    "    x_scale = torch.mean(torch.abs(x))\n",
    "    x /= x_scale\n",
    "    return x\n",
    "\n",
    "class MNIST_loader(data.Dataset):\n",
    "    \"\"\"This class is needed to processing batches for the dataloader.\"\"\"\n",
    "    def __init__(self, data, target1, target2, transform):\n",
    "        self.data = data\n",
    "        self.target1 = target1\n",
    "        self.target2 = target2\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"return transformed items.\"\"\"\n",
    "        x = self.data[index]\n",
    "        y1 = self.target1[index]\n",
    "        y2 = self.target2[index]\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(x.numpy(), mode='L')\n",
    "            x = self.transform(x)\n",
    "        return x, y1, y2\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"number of samples.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def get_mnist(args, data_dir='./data/mnist/'):\n",
    "    #get dataloders\n",
    "    # min, max values for the normal data, where the anormal class is the ith index of the list.\n",
    "    min_max = [(-0.82804, 20.108057),\n",
    "               (-0.8826562, 13.103283),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057),\n",
    "               (-0.8826562, 20.108057)]\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Lambda(lambda x: global_contrast_normalization(x)),\n",
    "                                    transforms.Normalize([min_max[args.anormal_class][0]],\n",
    "                                                         [min_max[args.anormal_class][1] \\\n",
    "                                                         -min_max[args.anormal_class][0]])])\n",
    "    train = datasets.MNIST(root=data_dir, train=True, download=True)\n",
    "    test = datasets.MNIST(root=data_dir, train=False, download=True)\n",
    "\n",
    "    x_train = train.data\n",
    "    y_train = train.targets\n",
    "\n",
    "    x_train = x_train[np.where(y_train!=args.anormal_class)]\n",
    "    y_train = y_train[np.where(y_train!=args.anormal_class)]\n",
    "    y_train = torch.Tensor([label if label<args.anormal_class else label-1 for label in y_train])\n",
    "    \n",
    "    N_train = int(x_train.shape[0]*0.8)\n",
    "    \n",
    "    x_val = x_train[N_train:]\n",
    "    y1_val = y_train[N_train:]\n",
    "    y2_val = np.where(y_train[N_train:]==args.anormal_class, 1, 0)\n",
    "    \n",
    "    data_val = MNIST_loader(x_val, y1_val, y2_val, transform)\n",
    "    dataloader_val = DataLoader(data_val, batch_size=args.batch_size, \n",
    "                                  shuffle=False, num_workers=0)\n",
    "    \n",
    "    x_train = x_train[:N_train]\n",
    "    y1_train = y_train[:N_train]\n",
    "    y2_train = np.where(y_train[:N_train]==args.anormal_class, 1, 0)\n",
    "                                    \n",
    "    data_train = MNIST_loader(x_train, y1_train, y2_train, transform)\n",
    "    dataloader_train = DataLoader(data_train, batch_size=args.batch_size, \n",
    "                                  shuffle=True, num_workers=0)\n",
    "    \n",
    "    x_test = test.data\n",
    "    y1_test = test.targets\n",
    "    y2_test = np.where(test.targets==args.anormal_class, 1, 0)\n",
    "    data_test = MNIST_loader(x_test, y1_test, y2_test, transform)\n",
    "    dataloader_test = DataLoader(data_test, batch_size=args.batch_size, \n",
    "                                  shuffle=True, num_workers=0)\n",
    "    return dataloader_train, dataloader_val, dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VaDE...\n",
      "42606/42606: [===============================>] - ETA 0.3sss\n",
      "Training VaDE... Epoch: 0, Loss: 2.837, Acc: 46.088\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing VaDE... Epoch: 0, Loss: 2.247, Acc: 59.141\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training VaDE... Epoch: 1, Loss: 2.193, Acc: 60.225\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing VaDE... Epoch: 1, Loss: 2.112, Acc: 63.219\n",
      "Weights saved.\n",
      "42606/42606: [===============================>] - ETA 0.1ss\n",
      "Training VaDE... Epoch: 2, Loss: nan, Acc: 33.954\n",
      "10652/10652: [===============================>] - ETA 0.0s\n",
      "Testing VaDE... Epoch: 2, Loss: nan, Acc: 11.116\n",
      "22656/42606: [================>...............] - ETA 8.4ss"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-681ce5e810d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mvade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerVaDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mvade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Class-outlier/vade/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_VaDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_VaDE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Class-outlier/vade/train.py\u001b[0m in \u001b[0;36mtrain_VaDE\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconst_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    num_epochs=500\n",
    "    num_epochs_ae=350\n",
    "    patience=100\n",
    "    lr=1e-4\n",
    "    lr_ae = 1e-4\n",
    "    lr_milestones=[50, 100, 150]\n",
    "    lr_milestones_ae = [250]\n",
    "    batch_size=128\n",
    "    pretrain=False\n",
    "    latent_dim=10\n",
    "    anormal_class=1\n",
    "    kl_mul = 1\n",
    "    cl_mul = 1\n",
    "    rec_mul = 1\n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataloader_train, dataloader_val, dataloader_test = get_mnist(args)\n",
    "\n",
    "vade = TrainerVaDE(args, dataloader_train, dataloader_val, device)\n",
    "vade.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vade.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(values, values_t, metric):\n",
    "    plt.plot(np.arange(len(values)), values, c='k', label='train')\n",
    "    plt.plot(np.arange(len(values_t)), values_t, c='b', label='test')\n",
    "    plt.title('VaDE {}'.format(metric))\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(np.array(vade.rec), np.array(vade.rec_t), 'Reconstruction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(np.array(vade.acc), np.array(vade.acc_t), 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(np.array(vade.dkl), np.array(vade.dkl_t), 'DKL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = []\n",
    "labels = []\n",
    "mus = []\n",
    "vade.VaDE.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, _ in dataloader_train:\n",
    "        x = x.float().to(device)\n",
    "        x_hat, mu, sigma, z = vade.VaDE(x)\n",
    "        mus.append(mu.detach().cpu())\n",
    "        latents.append(z.detach().cpu())\n",
    "        labels.append(y.cpu())\n",
    "labels = torch.cat(labels).numpy()\n",
    "latents = torch.cat(latents).numpy()\n",
    "mus = torch.cat(mus).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=2).fit_transform(latents[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cmap = plt.get_cmap('jet', 10)\n",
    "plt.scatter(x_embedded[:, 0], x_embedded[:, 1], c=labels[:2000], \n",
    "            s=10, alpha=1, marker='.', cmap=cmap)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=2).fit_transform(mus[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cmap = plt.get_cmap('jet', 10)\n",
    "plt.scatter(x_embedded[:, 0], x_embedded[:, 1], c=labels[:2000], \n",
    "            s=10, alpha=1, marker='.', cmap=cmap)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def eval(net, dataloader, device):\n",
    "    \"\"\"Testing the VaDE model\"\"\"\n",
    "\n",
    "    scores = []\n",
    "    latents = []\n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "    net.eval()\n",
    "    print('Testing...')\n",
    "    with torch.no_grad():\n",
    "        for x, y1, y2 in dataloader:\n",
    "            x = x.float().to(device)\n",
    "            x_hat, _, _, z = net(x)\n",
    "            score = F.mse_loss(x_hat, x, reduction='none')\n",
    "            score = torch.sum(score, dim=1)\n",
    "\n",
    "            scores.append(score.detach().cpu())\n",
    "            latents.append(z.detach().cpu())\n",
    "            labels1.append(y1.cpu())\n",
    "            labels2.append(y2.cpu())\n",
    "            \n",
    "    labels1, labels2 = torch.cat(labels1).numpy(), torch.cat(labels2).numpy(), \n",
    "    scores, latents = torch.cat(scores).numpy(), torch.cat(latents).numpy()\n",
    "    print('ROC AUC score: {:.3f}'.format(roc_auc_score(labels2, scores)))\n",
    "    return labels1, labels2, scores, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1, labels2, scores, latent = eval(vade.VaDE, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=2).fit_transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cmap = plt.get_cmap('jet', 4)\n",
    "plt.scatter(x_embedded[:, 0][labels2==0], x_embedded[:, 1][labels2==0],\n",
    "            s=15, alpha=0.5, marker='.')\n",
    "plt.scatter(x_embedded[:, 0][labels2!=0], x_embedded[:, 1][labels2!=0], \n",
    "            c=labels2[labels2!=0].reshape(-1,),\n",
    "            s=150, cmap=cmap, marker='*')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_in = scores[labels1==0]\n",
    "scores_out = scores[labels1==1]\n",
    "\n",
    "scores_ELL = scores[labels2==1]\n",
    "scores_TDE = scores[labels2==2]\n",
    "scores_SNIIb = scores[labels2==3]\n",
    "scores_WRayot = scores[labels2==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scores_in, bins=10, color='b', alpha=0.3, density=True, label='Inlier')\n",
    "plt.hist(scores_out, bins=15, color='r', alpha=0.3, density=True, label='Outlier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ALeRCELoader(object):\n",
    "    def __init__(self, dataset, normal_class, mode=\"train\", scaler=None):\n",
    "        \n",
    "        data = pd.read_pickle('{}_data.pkl'.format(dataset))\n",
    "        data = data[(data['n_det_1']>=10) & (data['n_det_2']>=10)]\n",
    "        importances = np.load('importances.npy').item()\n",
    "        x = data[importances['periodic_importance']]\n",
    "        y = data[['classALeRCE', 'hierClass', 'outClass']]\n",
    "        \n",
    "        if scaler is None:\n",
    "            scaler = QuantileTransformer(n_quantiles=5)\n",
    "            scaler.fit(x)\n",
    "        self.scaler = scaler\n",
    "        x = scaler.transform(x)\n",
    "        x[np.isnan(x)] = 0\n",
    "        \n",
    "        anormal_classes = ['Periodic', 'Transient', 'Stochastic']\n",
    "        anormal_classes.remove(normal_class)\n",
    "        \n",
    "        if mode =='train' or mode=='val':\n",
    "            self.x = x[y.hierClass==normal_class]\n",
    "            \n",
    "            y1 = y.hierClass[y.hierClass==normal_class]\n",
    "            y1 = np.where(y1==normal_class, 0, 1)\n",
    "            self.y1 = y1.reshape(y1.shape[0],).astype('int8')\n",
    "            \n",
    "            y2 = y.classALeRCE[y.hierClass==normal_class]\n",
    "            print(np.unique(y2))\n",
    "            for i, class_ in enumerate(np.unique(y2)):\n",
    "                y2 = np.where(y2==class_, i, y2)\n",
    "            self.y2 = y2.reshape(y2.shape[0],).astype('int8')\n",
    "            \n",
    "        elif mode=='test':\n",
    "            self.x = x\n",
    "            \n",
    "            y1 = y.hierClass\n",
    "            y1 = np.where(y1==normal_class, 0, 1)\n",
    "            self.y1 = y1.reshape(y1.shape[0],).astype('int8')\n",
    "\n",
    "            y2 = y.hierClass\n",
    "            y2 = np.where(y2==normal_class, 0, y2)\n",
    "            for i, anormal_class in enumerate(anormal_classes):\n",
    "                print(anormal_class)\n",
    "                y2 = np.where(y2==anormal_class, i+1, y2)\n",
    "            self.y2 = y2.reshape(y2.shape[0],).astype('int8')\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of images in the object dataset.\n",
    "        \"\"\"\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return np.float32(self.x[index]), np.float32(self.y1[index]), np.float32(self.y2[index])\n",
    "        \n",
    "\n",
    "def get_ALeRCE_data(batch_size, dataset, normal_class, mode='train', scaler=None):\n",
    "    \"\"\"Build and return data loader.\"\"\"\n",
    "    shuffle=True\n",
    "    \n",
    "    data = ALeRCELoader(dataset, normal_class, mode=mode, scaler=scaler)\n",
    "    if mode == 'train':\n",
    "        class_sample_count = np.unique(data.y2[:,0], return_counts=True)[1]\n",
    "        weights = 1. / torch.Tensor(class_sample_count)\n",
    "        samples_weight = np.array([weights[t] for t in data.y2[:,0]])\n",
    "        samples_weight = torch.from_numpy(samples_weight)\n",
    "        sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), \n",
    "                                                                 len(samples_weight))\n",
    "        data_loader = DataLoader(dataset=data,\n",
    "                                 batch_size=batch_size, sampler=sampler)\n",
    "    else:\n",
    "        data_loader = DataLoader(dataset=data,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False)\n",
    "    return data_loader, data.scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test, _ = get_ALeRCE_data(args.batch_size, 'test', 'Periodic', mode='test', scaler=scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1, labels2, scores, latent = eval(vade.VaDE, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=2).fit_transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = labels2.reshape(-1,)\n",
    "plt.figure(figsize=(8,8))\n",
    "cmap = plt.get_cmap('jet', 4)\n",
    "plt.scatter(x_embedded[:, 0][labels2==0], x_embedded[:, 1][labels2==0],\n",
    "            s=5, alpha=0.5, marker='.')\n",
    "plt.scatter(x_embedded[:, 0][labels2!=0], x_embedded[:, 1][labels2!=0], \n",
    "            c=labels2[labels2!=0].reshape(-1,), alpha=0.5,\n",
    "            s=5, cmap=cmap, marker='*')\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_in = scores[labels1==0]\n",
    "scores_out = scores[labels1==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scores_in, bins=10, color='b', alpha=0.3, density=True, label='Inlier')\n",
    "plt.hist(scores_out, bins=15, color='r', alpha=0.3, density=True, label='Outlier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
