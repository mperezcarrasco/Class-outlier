{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from classvdd.train import TrainerClasSVDD\n",
    "from classvdd.test import eval\n",
    "from preprocess import get_ALeRCE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 0, Loss: 0.169\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 0, Loss: 0.184\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 1, Loss: 0.154\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 1, Loss: 0.175\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 2, Loss: 0.141\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 2, Loss: 0.165\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 3, Loss: 0.129\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 3, Loss: 0.155\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 4, Loss: 0.119\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 4, Loss: 0.148\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 5, Loss: 0.109\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 5, Loss: 0.137\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 6, Loss: 0.101\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 6, Loss: 0.133\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 7, Loss: 0.093\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 7, Loss: 0.127\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 8, Loss: 0.086\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 8, Loss: 0.121\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 9, Loss: 0.080\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 9, Loss: 0.115\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 10, Loss: 0.074\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 10, Loss: 0.111\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 11, Loss: 0.068\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 11, Loss: 0.108\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 12, Loss: 0.064\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 12, Loss: 0.104\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 13, Loss: 0.060\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 13, Loss: 0.102\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 14, Loss: 0.055\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 14, Loss: 0.0994\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 15, Loss: 0.052\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 15, Loss: 0.0975\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 16, Loss: 0.049\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 16, Loss: 0.0966\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 17, Loss: 0.046\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 17, Loss: 0.0937\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 18, Loss: 0.044\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 18, Loss: 0.095\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 19, Loss: 0.041\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 19, Loss: 0.0887\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 20, Loss: 0.040\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 20, Loss: 0.0875\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 21, Loss: 0.038\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 21, Loss: 0.0864\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 22, Loss: 0.036\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 22, Loss: 0.0886\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 23, Loss: 0.035\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 23, Loss: 0.0844\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 24, Loss: 0.034\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 24, Loss: 0.0864\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 25, Loss: 0.033\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 25, Loss: 0.0826\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 26, Loss: 0.032\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 26, Loss: 0.0832\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 27, Loss: 0.031\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 27, Loss: 0.0817\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 28, Loss: 0.030\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 28, Loss: 0.0812\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 29, Loss: 0.030\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 29, Loss: 0.0802\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 30, Loss: 0.029\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 30, Loss: 0.0826\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 31, Loss: 0.028\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 31, Loss: 0.0808\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 32, Loss: 0.028\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 32, Loss: 0.0783\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 33, Loss: 0.027\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 33, Loss: 0.0841\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 34, Loss: 0.027\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 34, Loss: 0.0783\n",
      "Weights saved.\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 35, Loss: 0.027\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 35, Loss: 0.0839\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 36, Loss: 0.026\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 36, Loss: 0.0829\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 37, Loss: 0.026\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 37, Loss: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 38, Loss: 0.026\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 38, Loss: 0.0785\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 39, Loss: 0.025\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 39, Loss: 0.0812\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 40, Loss: 0.025\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 40, Loss: 0.0818\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 41, Loss: 0.024\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 41, Loss: 0.081\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 42, Loss: 0.024\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 42, Loss: 0.0833\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 43, Loss: 0.024\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 43, Loss: 0.084\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 44, Loss: 0.024\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 44, Loss: 0.0815\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 45, Loss: 0.023\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 45, Loss: 0.0818\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 46, Loss: 0.023\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 46, Loss: 0.0806\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 47, Loss: 0.023\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 47, Loss: 0.0842\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 48, Loss: 0.023\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 48, Loss: 0.084\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 49, Loss: 0.022\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 49, Loss: 0.0829\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 50, Loss: 0.022\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 50, Loss: 0.0852\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 51, Loss: 0.022\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 51, Loss: 0.0852\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 52, Loss: 0.022\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 52, Loss: 0.085\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 53, Loss: 0.022\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 53, Loss: 0.0823\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 54, Loss: 0.021\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 54, Loss: 0.0889\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 55, Loss: 0.021\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 55, Loss: 0.087\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 56, Loss: 0.021\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 56, Loss: 0.0878\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 57, Loss: 0.021\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 57, Loss: 0.0833\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 58, Loss: 0.021\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 58, Loss: 0.0891\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 59, Loss: 0.020\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 59, Loss: 0.0857\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 60, Loss: 0.020\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 60, Loss: 0.0869\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 61, Loss: 0.020\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 61, Loss: 0.0856\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 62, Loss: 0.020\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 62, Loss: 0.0841\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 63, Loss: 0.020\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 63, Loss: 0.086\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 64, Loss: 0.020\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 64, Loss: 0.0861\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 65, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 65, Loss: 0.0837\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 66, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 66, Loss: 0.0843\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 67, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 67, Loss: 0.0846\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 68, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 68, Loss: 0.0854\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 69, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 69, Loss: 0.0883\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 70, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 70, Loss: 0.0891\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 71, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 71, Loss: 0.0879\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 72, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 72, Loss: 0.0876\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 73, Loss: 0.019\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 73, Loss: 0.0899\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 74, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 74, Loss: 0.0862\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 75, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 75, Loss: 0.0886\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 76, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 76, Loss: 0.0909\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 77, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 77, Loss: 0.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 78, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 78, Loss: 0.0858\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 79, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 79, Loss: 0.0894\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 80, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 80, Loss: 0.0897\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 81, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 81, Loss: 0.0887\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 82, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 82, Loss: 0.0878\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 83, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 83, Loss: 0.0897\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 84, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 84, Loss: 0.0896\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 85, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 85, Loss: 0.088\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 86, Loss: 0.018\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 86, Loss: 0.0892\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 87, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 87, Loss: 0.088\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 88, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 88, Loss: 0.0884\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 89, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 89, Loss: 0.0921\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 90, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 90, Loss: 0.0912\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 91, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 91, Loss: 0.089\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 92, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 92, Loss: 0.0888\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 93, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 93, Loss: 0.0902\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 94, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 94, Loss: 0.0896\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 95, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 95, Loss: 0.0906\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 96, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 96, Loss: 0.0894\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 97, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 97, Loss: 0.0924\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 98, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 98, Loss: 0.0889\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 99, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 99, Loss: 0.0911\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 100, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 100, Loss: 0.0907\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 101, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 101, Loss: 0.091\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 102, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 102, Loss: 0.0892\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 103, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 103, Loss: 0.0898\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 104, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 104, Loss: 0.0888\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 105, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 105, Loss: 0.0917\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 106, Loss: 0.017\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 106, Loss: 0.0934\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 107, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 107, Loss: 0.0908\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 108, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 108, Loss: 0.0925\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 109, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 109, Loss: 0.0929\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 110, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 110, Loss: 0.0917\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 111, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 111, Loss: 0.0922\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 112, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 112, Loss: 0.0941\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 113, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 113, Loss: 0.0929\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 114, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 114, Loss: 0.0915\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 115, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 115, Loss: 0.0955\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 116, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 116, Loss: 0.0929\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 117, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 117, Loss: 0.0956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 118, Loss: 0.016\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 118, Loss: 0.0917\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 119, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 119, Loss: 0.092\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 120, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 120, Loss: 0.0928\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 121, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 121, Loss: 0.0939\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 122, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 122, Loss: 0.0915\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 123, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 123, Loss: 0.0909\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 124, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 124, Loss: 0.0958\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 125, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 125, Loss: 0.0904\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 126, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 126, Loss: 0.0946\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 127, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 127, Loss: 0.0915\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 128, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 128, Loss: 0.0931\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 129, Loss: 0.014\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 129, Loss: 0.0946\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 130, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 130, Loss: 0.0961\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 131, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 131, Loss: 0.0947\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 132, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 132, Loss: 0.0921\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 133, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 133, Loss: 0.0935\n",
      "27058/27058: [===============================>] - ETA 0.0s\n",
      "Training ClasSVDD... Epoch: 134, Loss: 0.015\n",
      "4741/4741: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 134, Loss: 0.0958\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    num_epochs=1000\n",
    "    patience=100\n",
    "    lr=1e-6\n",
    "    weight_decay= 0.5e-2\n",
    "    lr_milestones=[150, 300, 450, 600]\n",
    "    batch_size=128\n",
    "    pretrain=True\n",
    "    latent_dim=32   \n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataloader_train, scaler, classes = get_ALeRCE_data(args.batch_size, 'train', mode='train')\n",
    "dataloader_val, _, _ = get_ALeRCE_data(args.batch_size, 'val', mode='test', scaler=scaler)\n",
    "dataloader_test, _, _ = get_ALeRCE_data(args.batch_size, 'test', mode='test', scaler=scaler)\n",
    "\n",
    "classvdd = TrainerClasSVDD(args, dataloader_train, dataloader_val, device, scaler)\n",
    "classvdd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "ROC AUC score: 0.809\n"
     ]
    }
   ],
   "source": [
    "labels1, labels2, scores = eval(classvdd.net, classvdd.c, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_in = scores[labels1==0]\n",
    "scores_out = scores[labels1==1]\n",
    "\n",
    "scores_ELL = scores[labels2==1]\n",
    "scores_TDE = scores[labels2==2]\n",
    "scores_SNIIb = scores[labels2==3]\n",
    "scores_WRayot = scores[labels2==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4853edb828>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores_in[scores_in<20], bins=10, color='b', alpha=0.3, density=True, label='Inlier')\n",
    "plt.hist(scores_out, bins=20, color='r', alpha=0.3, density=True, label='Outlier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
