{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from classvdd.train import TrainerClasSVDD\n",
    "from classvdd.test import eval\n",
    "from preprocess import get_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    num_epochs=250\n",
    "    num_epochs_ae=350\n",
    "    patience=100\n",
    "    lr=1e-4\n",
    "    weight_decay=0.5e-6\n",
    "    weight_decay_ae=0.5e-3\n",
    "    lr_ae=1e-4\n",
    "    lr_milestones_ae=[250]\n",
    "    lr_milestones=[150]\n",
    "    batch_size=200\n",
    "    pretrain=True\n",
    "    latent_dim=32\n",
    "    anormal_class=5\n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataloader_train, dataloader_val, dataloader_test = get_mnist(args)\n",
    "\n",
    "classvdd = TrainerClasSVDD(args, dataloader_train, dataloader_val, device)\n",
    "\n",
    "#if args.pretrain:\n",
    "#    classvdd.pretrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 0, Loss: 1.265\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 0, Loss: 0.706\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 1, Loss: 0.629\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 1, Loss: 0.534\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 2, Loss: 0.517\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 2, Loss: 0.455\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 3, Loss: 0.453\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 3, Loss: 0.403\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 4, Loss: 0.407\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 4, Loss: 0.366\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 5, Loss: 0.375\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 5, Loss: 0.337\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 6, Loss: 0.349\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 6, Loss: 0.314\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 7, Loss: 0.327\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 7, Loss: 0.295\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 8, Loss: 0.310\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 8, Loss: 0.28\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 9, Loss: 0.294\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 9, Loss: 0.268\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 10, Loss: 0.282\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 10, Loss: 0.255\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 11, Loss: 0.270\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 11, Loss: 0.247\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 12, Loss: 0.261\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 12, Loss: 0.239\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 13, Loss: 0.253\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 13, Loss: 0.231\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 14, Loss: 0.246\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 14, Loss: 0.227\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 15, Loss: 0.240\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 15, Loss: 0.219\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 16, Loss: 0.235\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 16, Loss: 0.216\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 17, Loss: 0.229\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 17, Loss: 0.212\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 18, Loss: 0.226\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 18, Loss: 0.206\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 19, Loss: 0.221\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 19, Loss: 0.203\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 20, Loss: 0.217\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 20, Loss: 0.199\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 21, Loss: 0.214\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 21, Loss: 0.205\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 22, Loss: 0.211\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 22, Loss: 0.195\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 23, Loss: 0.208\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 23, Loss: 0.191\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 24, Loss: 0.205\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 24, Loss: 0.19\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 25, Loss: 0.203\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 25, Loss: 0.189\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 26, Loss: 0.201\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 26, Loss: 0.185\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 27, Loss: 0.199\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 27, Loss: 0.182\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 28, Loss: 0.197\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 28, Loss: 0.181\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 29, Loss: 0.195\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 29, Loss: 0.179\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 30, Loss: 0.193\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 30, Loss: 0.186\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 31, Loss: 0.191\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 31, Loss: 0.177\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 32, Loss: 0.190\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 32, Loss: 0.178\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 33, Loss: 0.188\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 33, Loss: 0.179\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 34, Loss: 0.188\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 34, Loss: 0.172\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 35, Loss: 0.185\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 35, Loss: 0.178\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 36, Loss: 0.185\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 36, Loss: 0.171\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 37, Loss: 0.183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 37, Loss: 0.169\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 38, Loss: 0.182\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 38, Loss: 0.168\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 39, Loss: 0.181\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 39, Loss: 0.168\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 40, Loss: 0.180\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 40, Loss: 0.168\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 41, Loss: 0.179\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 41, Loss: 0.166\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 42, Loss: 0.177\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 42, Loss: 0.165\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 43, Loss: 0.177\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 43, Loss: 0.164\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 44, Loss: 0.176\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 44, Loss: 0.163\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 45, Loss: 0.174\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 45, Loss: 0.164\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 46, Loss: 0.175\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 46, Loss: 0.162\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 47, Loss: 0.174\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 47, Loss: 0.16\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 48, Loss: 0.172\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 48, Loss: 0.161\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 49, Loss: 0.172\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 49, Loss: 0.159\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 50, Loss: 0.172\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 50, Loss: 0.162\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 51, Loss: 0.170\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 51, Loss: 0.159\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 52, Loss: 0.170\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 52, Loss: 0.158\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 53, Loss: 0.169\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 53, Loss: 0.158\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 54, Loss: 0.169\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 54, Loss: 0.159\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 55, Loss: 0.168\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 55, Loss: 0.156\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 56, Loss: 0.167\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 56, Loss: 0.158\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 57, Loss: 0.166\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 57, Loss: 0.156\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 58, Loss: 0.166\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 58, Loss: 0.156\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 59, Loss: 0.166\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 59, Loss: 0.158\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 60, Loss: 0.165\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 60, Loss: 0.157\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 61, Loss: 0.165\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 61, Loss: 0.153\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 62, Loss: 0.165\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 62, Loss: 0.157\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 63, Loss: 0.164\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 63, Loss: 0.153\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 64, Loss: 0.163\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 64, Loss: 0.151\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 65, Loss: 0.163\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 65, Loss: 0.153\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 66, Loss: 0.163\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 66, Loss: 0.151\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 67, Loss: 0.161\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 67, Loss: 0.152\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 68, Loss: 0.161\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 68, Loss: 0.153\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 69, Loss: 0.161\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 69, Loss: 0.152\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 70, Loss: 0.160\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 70, Loss: 0.152\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 71, Loss: 0.160\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 71, Loss: 0.15\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 72, Loss: 0.160\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 72, Loss: 0.149\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 73, Loss: 0.159\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 73, Loss: 0.149\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 74, Loss: 0.159\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 74, Loss: 0.148\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 75, Loss: 0.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 75, Loss: 0.15\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 76, Loss: 0.159\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 76, Loss: 0.148\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 77, Loss: 0.158\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 77, Loss: 0.147\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 78, Loss: 0.157\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 78, Loss: 0.148\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 79, Loss: 0.158\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 79, Loss: 0.147\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 80, Loss: 0.156\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 80, Loss: 0.147\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 81, Loss: 0.157\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 81, Loss: 0.146\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 82, Loss: 0.156\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 82, Loss: 0.147\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 83, Loss: 0.156\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 83, Loss: 0.146\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 84, Loss: 0.156\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 84, Loss: 0.147\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 85, Loss: 0.155\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 85, Loss: 0.144\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 86, Loss: 0.155\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 86, Loss: 0.147\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 87, Loss: 0.154\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 87, Loss: 0.153\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 88, Loss: 0.154\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 88, Loss: 0.145\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 89, Loss: 0.154\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 89, Loss: 0.143\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 90, Loss: 0.154\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 90, Loss: 0.143\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 91, Loss: 0.153\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 91, Loss: 0.144\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 92, Loss: 0.153\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 92, Loss: 0.146\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 93, Loss: 0.153\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 93, Loss: 0.143\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 94, Loss: 0.153\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 94, Loss: 0.146\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 95, Loss: 0.153\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 95, Loss: 0.142\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 96, Loss: 0.152\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 96, Loss: 0.143\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 97, Loss: 0.152\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 97, Loss: 0.142\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 98, Loss: 0.151\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 98, Loss: 0.142\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 99, Loss: 0.150\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 99, Loss: 0.142\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 100, Loss: 0.151\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 100, Loss: 0.141\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 101, Loss: 0.151\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 101, Loss: 0.144\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 102, Loss: 0.149\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 102, Loss: 0.141\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 103, Loss: 0.149\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 103, Loss: 0.146\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 104, Loss: 0.150\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 104, Loss: 0.142\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 105, Loss: 0.149\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 105, Loss: 0.139\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 106, Loss: 0.150\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 106, Loss: 0.14\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 107, Loss: 0.149\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 107, Loss: 0.14\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 108, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 108, Loss: 0.14\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 109, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 109, Loss: 0.14\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 110, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 110, Loss: 0.141\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 111, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 111, Loss: 0.139\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 112, Loss: 0.149\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 112, Loss: 0.139\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 113, Loss: 0.149\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 113, Loss: 0.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 114, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 114, Loss: 0.138\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 115, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 115, Loss: 0.139\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 116, Loss: 0.147\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 116, Loss: 0.139\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 117, Loss: 0.148\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 117, Loss: 0.137\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 118, Loss: 0.147\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 118, Loss: 0.139\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 119, Loss: 0.147\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 119, Loss: 0.141\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 120, Loss: 0.147\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 120, Loss: 0.142\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 121, Loss: 0.147\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 121, Loss: 0.137\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 122, Loss: 0.146\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 122, Loss: 0.137\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 123, Loss: 0.146\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 123, Loss: 0.136\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 124, Loss: 0.146\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 124, Loss: 0.138\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 125, Loss: 0.145\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 125, Loss: 0.137\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 126, Loss: 0.145\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 126, Loss: 0.136\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 127, Loss: 0.145\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 127, Loss: 0.137\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 128, Loss: 0.145\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 128, Loss: 0.135\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 129, Loss: 0.145\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 129, Loss: 0.143\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 130, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 130, Loss: 0.136\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 131, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 131, Loss: 0.136\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 132, Loss: 0.145\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 132, Loss: 0.135\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 133, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 133, Loss: 0.138\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 134, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 134, Loss: 0.135\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 135, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 135, Loss: 0.135\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 136, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 136, Loss: 0.137\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 137, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 137, Loss: 0.136\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 138, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 138, Loss: 0.135\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 139, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 139, Loss: 0.134\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 140, Loss: 0.144\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 140, Loss: 0.136\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 141, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 141, Loss: 0.135\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 142, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 142, Loss: 0.139\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 143, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 143, Loss: 0.133\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 144, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 144, Loss: 0.137\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 145, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 145, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 146, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 146, Loss: 0.136\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 147, Loss: 0.142\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 147, Loss: 0.134\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 148, Loss: 0.142\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 148, Loss: 0.135\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 149, Loss: 0.143\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 149, Loss: 0.134\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 150, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 150, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 151, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 151, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 152, Loss: 0.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 152, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 153, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 153, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 154, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 154, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 155, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 155, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 156, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 156, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 157, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 157, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 158, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 158, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 159, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 159, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 160, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 160, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 161, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 161, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 162, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 162, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 163, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 163, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 164, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 164, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 165, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 165, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 166, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 166, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 167, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 167, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 168, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 168, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 169, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 169, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 170, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 170, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 171, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 171, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 172, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 172, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 173, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 173, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 174, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 174, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 175, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 175, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 176, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 176, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 177, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 177, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 178, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 178, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 179, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 179, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 180, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 180, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 181, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 181, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 182, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 182, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 183, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 183, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 184, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 184, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 185, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 185, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 186, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 186, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 187, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 187, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 188, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 188, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 189, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 189, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 190, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 190, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 191, Loss: 0.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 191, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 192, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 192, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 193, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 193, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 194, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 194, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 195, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 195, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 196, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 196, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 197, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 197, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 198, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 198, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 199, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 199, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 200, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 200, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 201, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 201, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 202, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 202, Loss: 0.133\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 203, Loss: 0.140\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 203, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 204, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 204, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 205, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 205, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 206, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 206, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 207, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 207, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 208, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 208, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 209, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 209, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 210, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 210, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 211, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 211, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 212, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 212, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 213, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 213, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 214, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 214, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 215, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 215, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 216, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 216, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 217, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 217, Loss: 0.132\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 218, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 218, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 219, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 219, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 220, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 220, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 221, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 221, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 222, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 222, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 223, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 223, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 224, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 224, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 225, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 225, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 226, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 226, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 227, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 227, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 228, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 228, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 229, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 229, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 230, Loss: 0.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 230, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 231, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 231, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 232, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 232, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 233, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 233, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 234, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 234, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 235, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 235, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 236, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 236, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 237, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 237, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 238, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 238, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 239, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 239, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 240, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 240, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 241, Loss: 0.138\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 241, Loss: 0.132\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 242, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 242, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 243, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 243, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 244, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 244, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 245, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 245, Loss: 0.131\n",
      "Weights saved.\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 246, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 246, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 247, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.0s\n",
      "Testing ClasSVDD... Epoch: 247, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 248, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 248, Loss: 0.131\n",
      "43663/43663: [===============================>] - ETA 0.1ss\n",
      "Training ClasSVDD... Epoch: 249, Loss: 0.139\n",
      "10916/10916: [===============================>] - ETA 0.1s\n",
      "Testing ClasSVDD... Epoch: 249, Loss: 0.131\n"
     ]
    }
   ],
   "source": [
    "classvdd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('classvdd/weights/model_parameters_5.pth')\n",
    "classvdd.net.load_state_dict(state_dict['model'])\n",
    "classvdd.c = torch.Tensor(state_dict['center']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def eval(net, c, dataloader, device):\n",
    "    \"\"\"Testing the Deep SVDD model\"\"\"\n",
    "\n",
    "    scores = []\n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "    net.eval()\n",
    "    print('Testing...')\n",
    "    with torch.no_grad():\n",
    "        for x, y1, y2 in dataloader:\n",
    "            x = x.float().to(device)            \n",
    "            z = net(x)\n",
    "            score = torch.min(torch.sum((z.unsqueeze(1) - c) ** 2, dim=2),dim=1)[0]\n",
    "            \n",
    "            scores.append(score.detach().cpu())\n",
    "            labels1.append(y1.cpu())\n",
    "            labels2.append(y2.cpu())\n",
    "    labels1, labels2, scores = torch.cat(labels1).numpy(), torch.cat(labels2).numpy(), torch.cat(scores).numpy()\n",
    "    print('ROC AUC score: {:.3f}'.format(roc_auc_score(labels2, scores)))\n",
    "    return labels1, labels2, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "ROC AUC score: 0.939\n"
     ]
    }
   ],
   "source": [
    "labels1, labels2, scores = eval(classvdd.net, classvdd.c, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_in = scores[labels2==0]\n",
    "scores_out = scores[labels2==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3ba5fd9be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores_in, bins=100, color='b', alpha=0.3, density=True, label='Inlier')\n",
    "plt.hist(scores_out, bins=100, color='r', alpha=0.3, density=True, label='Outlier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
